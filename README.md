# Medical Question-Answering System

This repository focuses on developing a medical question-answering system. We opted for a Retrieval-Augmented Generation (RAG) approach, with the retriever based on the BM25+ algorithm and the generator powered by the Qwen2-0.5B-Instruct LLM model.

## Technical Setup
The code is provided in the notebook (`medical_assistant.ipynb`) included in this repository. It assumes the presence of a `dataset.csv` file with "question" and "answer" columns, placed in the same folder. The notebook is designed to run on Google Colab and is optimized for workloads supported by a T4 GPU.

## Results
We achieved a 90% accuracy at the top 20 results (ACC@20) for our retriever, demonstrating its effectiveness as part of our RAG solution. However, for performance considerations, we used a smaller top-k value for the examples in the notebook.

## Points for Improvement
1. **Enhancing the Retriever**  
   BM25 is a robust baseline for information retrieval, as evidenced by [a paper where I am a co-author](https://arxiv.org/abs/2105.05686). The ACC@20 (and other information retrieval metrics) can be improved by conducting a grid search to identify the optimal BM25+ hyperparameters (e.g., \(k\), \(b\), and \(\delta\)). This process should be validated through K-Fold Cross Validation to ensure reliable performance. Exploring this optimization should precede adopting hybrid systems or systems entirely based on semantic search, which would add complexity and computational costs.

2. **Improving the Generator**  
   The generator occasionally fails to produce accurate answers, regardless of the BM25 retriever's performance. If increasing the budget for a more advanced LLM is not feasible, alternative strategies should be explored. These include:  
   - **Prompt Engineering:** Refining prompts to better guide the generator.  
   - **Multi-Agent Workflows:** Utilizing tools like LangChain or LangGraph to put together multiple agents that improve the output after several prompting steps, reducing the likelihood of generating inappropriate outputs.

3. **Expanding Evaluation Metrics**  
   Our evaluation can be enhanced by directly assessing the generator's performance. LLM-as-a-judge approaches, where a larger LLM (or an ensemble of models) evaluates the generated answers, would ensure a more comprehensive understanding of our systemâ€™s overall accuracy and appropriateness.